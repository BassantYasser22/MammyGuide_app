from sentence_transformers import SentenceTransformer
import numpy as np
import json
from sklearn.metrics.pairwise import cosine_similarity

# 1. ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Ø­Ø¯ÙŠØ« ÙˆÙ…ØªØ·ÙˆØ±
model = SentenceTransformer("intfloat/multilingual-e5-base")

# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§
with open("temp db.json", "r", encoding="utf-8") as file:
    video_data = json.load(file)

# 3. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„ÙˆØµÙ
video_titles = [video["title"] for video in video_data]
video_descriptions = [video["description"] for video in video_data]
video_texts = [f"{title}. {description}" for title, description in zip(video_titles, video_descriptions)]

# 4. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù€ embeddings
video_embeddings = model.encode(video_texts, normalize_embeddings=True)

# 5. Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø«
def search_videos(query, top_n=5):
    query_embedding = model.encode([query], normalize_embeddings=True)
    similarities = cosine_similarity(query_embedding, video_embeddings)[0]

    sorted_indices = np.argsort(similarities)[::-1][:top_n]
    
    print("\nğŸ” Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:\n")
    for idx in sorted_indices:
        print(f"ğŸ¥ {video_titles[idx]} (Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarities[idx]:.2f})")

# 6. Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø«
while True:
    search_query = input("\nğŸ“ Ø£Ø¯Ø®Ù„ Ø¬Ù…Ù„Ø© Ø§Ù„Ø¨Ø­Ø« (Ø£Ùˆ Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«): ")
    if search_query.lower() == "Ø®Ø±ÙˆØ¬":
        print("\nğŸ‘‹ ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«. Ø´ÙƒØ±Ù‹Ø§ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬!")
        break
    search_videos(search_query)
