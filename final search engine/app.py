from fastapi import FastAPI
from pydantic import BaseModel
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
import sys
import requests

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
model = SentenceTransformer("intfloat/multilingual-e5-base")

# 2. Ø¯ÙˆØ§Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§
def load_dataset_from_huggingface():
    print("ğŸŒ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† HuggingFace...")
    dataset = load_dataset("Eng-Bassant/parenting-videos-dataset", download_mode="force_redownload")
    return dataset["train"]

def load_dataset_from_json(url):
    print("ğŸŒ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø±Ø§Ø¨Ø· JSON...")
    response = requests.get(url)
    return response.json()

def load_dataset_local(filepath):
    print("ğŸ“‚ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù Ù…Ø­Ù„ÙŠ...")
    with open(filepath, "r", encoding="utf-8") as f:
        return json.load(f)

# 3. ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§
video_titles = []
video_descriptions = []

try:
    # Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©: HuggingFace
    video_data = load_dataset_from_huggingface()
    
    if "videos" in video_data.features:
        video_titles = [video["title"] for video in video_data["videos"]]
        video_descriptions = [video["description"] for video in video_data["videos"]]
    else:
        video_titles = [video["title"] for video in video_data]
        video_descriptions = [video["description"] for video in video_data]

except Exception as e1:
    print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§ Ù…Ù† HuggingFace: {e1}")
    try:
        # ØªØ§Ù†ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø©: Ø±Ø§Ø¨Ø· JSON Ù…Ø¨Ø§Ø´Ø±
        url = "https://huggingface.co/datasets/Eng-Bassant/parenting-videos-dataset/resolve/main/temp%20db.json"
        video_data = load_dataset_from_json(url)

        video_titles = [video["title"] for video in video_data]
        video_descriptions = [video["description"] for video in video_data]

    except Exception as e2:
        print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {e2}")
        try:
            # ØªØ§Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø©: Ù…Ù„Ù Ù…Ø­Ù„ÙŠ
            filepath = "parenting_videos.json"
            video_data = load_dataset_local(filepath)

            video_titles = [video["title"] for video in video_data]
            video_descriptions = [video["description"] for video in video_data]

        except Exception as e3:
            print(f"âŒ ÙØ´Ù„ ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø§Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§: {e3}")
            sys.exit(1)

# ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†ØµÙˆØµ ÙˆÙ†Ø¹Ù…Ù„ Embeddings
video_texts = [f"{title}. {description}" for title, description in zip(video_titles, video_descriptions)]
video_embeddings = model.encode(video_texts, normalize_embeddings=True)

print(f"\nâœ… ØªÙ… ØªØ¬Ù‡ÙŠØ² {len(video_titles)} ÙÙŠØ¯ÙŠÙˆ Ù„Ù„Ø¨Ø­Ø«.")

# 4. ØªØ¬Ù‡ÙŠØ² FastAPI
app = FastAPI()

# Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø±ÙŠÙƒÙˆØ³Øª
class SearchRequest(BaseModel):
    query: str
    top_k: int = 7

# 5. Endpoint Ù„Ù„Ø¨Ø­Ø«
@app.post("/search")
def search(request: SearchRequest):
    try:
        query_embedding = model.encode([request.query], normalize_embeddings=True)
        similarities = cosine_similarity(query_embedding, video_embeddings)[0]
        sorted_indices = np.argsort(similarities)[::-1][:request.top_k]
        results = [{"title": video_titles[idx], "description": video_descriptions[idx]} for idx in sorted_indices]
        return {"results": results}
    except Exception as e:
        return {"error": str(e)}
